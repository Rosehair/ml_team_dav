{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lasagne\n",
    "* lasagne is a library for neural network building and training\n",
    "* it's a low-level library with almost seamless integration with theano\n",
    "\n",
    "For a demo we shall solve the same digit recognition problem, but at a different scale\n",
    "* images are now 28x28\n",
    "* 10 different digits\n",
    "* 50k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 28, 28) (50000,)\n"
     ]
    }
   ],
   "source": [
    "from mnist import load_dataset\n",
    "X_train,y_train,X_val,y_val,X_test,y_test = load_dataset()\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_X = T.tensor4(\"X\")\n",
    "\n",
    "#input dimention (None means \"Arbitrary\" and only works at  the first axes [samples])\n",
    "input_shape = [None,1,28,28]\n",
    "\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 28, 28)\n",
      "(None, 20, 28, 28)\n",
      "(None, 20, 14, 14)\n",
      "(None, 10, 14, 14)\n",
      "(None, 10, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "#Input layer (auxilary)\n",
    "l = InputLayer(shape = input_shape,input_var=input_X)\n",
    "# l2 = DropoutLayer(l1, p=0.2)\n",
    "# l6 = DenseLayer(l2, num_units=500,nonlinearity = lasagne.nonlinearities.leaky_rectify)\n",
    "# l6 = DenseLayer(l2, num_units=10,nonlinearity = lasagne.nonlinearities.leaky_rectify\n",
    "\n",
    "print(l.output_shape)\n",
    "l = Conv2DLayer(l, num_filters=20, filter_size=(5, 5), nonlinearity=lasagne.nonlinearities.linear, pad = 'same')\n",
    "print(l.output_shape)\n",
    "l = MaxPool2DLayer(l, pool_size=(2, 2))\n",
    "print(l.output_shape)\n",
    "l = Conv2DLayer(l, num_filters=10, filter_size=(5, 5), nonlinearity=lasagne.nonlinearities.linear, pad = 'same')\n",
    "print(l.output_shape)\n",
    "l = MaxPool2DLayer(l, pool_size=(2, 2))\n",
    "print(l.output_shape)\n",
    "# l = Conv2DLayer(l, num_filters=10, filter_size=(5, 5), nonlinearity=lasagne.nonlinearities.rectify, pad = 'same')\n",
    "# print(l.output_shape)\n",
    "# l = MaxPool2DLayer(l, pool_size=(2, 2))\n",
    "# print(l.output_shape)\n",
    "# l5 = DropoutLayer(l4, p=0.5)\n",
    "# l2 = Pool1DLayer(l1, pool_size=(1,1,16,16))\n",
    "l = DropoutLayer(l, p=0.6)\n",
    "l = DenseLayer(l, num_units = 1000,nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "#fully connected output layer that takes dense_1 as input and has 10 neurons (1 for each digit)\n",
    "#We use softmax nonlinearity to make probabilities add up to 1\n",
    "l_out = DenseLayer(l, num_units = 10,nonlinearity=lasagne.nonlinearities.softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#network prediction (theano-transformation)\n",
    "y_predicted = lasagne.layers.get_output(l_out)\n",
    "y_test_predicted = lasagne.layers.get_output(l_out, deterministic = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b, W, b]\n"
     ]
    }
   ],
   "source": [
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(l_out)\n",
    "print(all_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Than you could simply\n",
    "* define loss function manually\n",
    "* compute error gradient over all weights\n",
    "* define updates\n",
    "* But that's a whole lot of work and life's short\n",
    "  * not to mention life's too short to wait for SGD to converge\n",
    "\n",
    "Instead, we shall use Lasagne builtins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(y_predicted,target_y).mean()\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_test_predicted,target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adadelta(loss, all_weights,learning_rate=0.3, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X,target_y],[loss,accuracy],updates= updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X,target_y],accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's all, now let's train it!\n",
    "* We got a lot of data, so it's recommended that you use SGD\n",
    "* So let's implement a function that splits the training sample into minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# An auxilary function that returns mini-batches for neural network training\n",
    "\n",
    "#Parameters\n",
    "# inputs - a tensor of images with shape (many, 1, 28, 28), e.g. X_train\n",
    "# outputs - a vector of answers for corresponding images e.g. Y_train\n",
    "#batch_size - a single number - the intended size of each batches\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize):\n",
    "    assert len(inputs) == len(targets)\n",
    "    indices = np.arange(len(inputs))\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1000 took 70.250s\n",
      "  training loss (in-iteration):\t\t0.023741\n",
      "  train accuracy:\t\t99.88 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 2 of 1000 took 70.286s\n",
      "  training loss (in-iteration):\t\t0.022816\n",
      "  train accuracy:\t\t99.88 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 3 of 1000 took 67.706s\n",
      "  training loss (in-iteration):\t\t0.023069\n",
      "  train accuracy:\t\t99.89 %\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 4 of 1000 took 72.194s\n",
      "  training loss (in-iteration):\t\t0.022371\n",
      "  train accuracy:\t\t99.89 %\n",
      "  validation accuracy:\t\t99.29 %\n",
      "Epoch 5 of 1000 took 70.723s\n",
      "  training loss (in-iteration):\t\t0.023568\n",
      "  train accuracy:\t\t99.91 %\n",
      "  validation accuracy:\t\t99.20 %\n",
      "Epoch 6 of 1000 took 70.749s\n",
      "  training loss (in-iteration):\t\t0.022585\n",
      "  train accuracy:\t\t99.88 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 7 of 1000 took 71.019s\n",
      "  training loss (in-iteration):\t\t0.020599\n",
      "  train accuracy:\t\t99.91 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 8 of 1000 took 70.303s\n",
      "  training loss (in-iteration):\t\t0.020162\n",
      "  train accuracy:\t\t99.91 %\n",
      "  validation accuracy:\t\t99.33 %\n",
      "Epoch 9 of 1000 took 69.911s\n",
      "  training loss (in-iteration):\t\t0.021178\n",
      "  train accuracy:\t\t99.90 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 10 of 1000 took 70.422s\n",
      "  training loss (in-iteration):\t\t0.022106\n",
      "  train accuracy:\t\t99.92 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 11 of 1000 took 69.469s\n",
      "  training loss (in-iteration):\t\t0.020877\n",
      "  train accuracy:\t\t99.92 %\n",
      "  validation accuracy:\t\t99.34 %\n",
      "Epoch 12 of 1000 took 67.512s\n",
      "  training loss (in-iteration):\t\t0.020813\n",
      "  train accuracy:\t\t99.93 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 13 of 1000 took 70.064s\n",
      "  training loss (in-iteration):\t\t0.020961\n",
      "  train accuracy:\t\t99.93 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 14 of 1000 took 69.653s\n",
      "  training loss (in-iteration):\t\t0.019742\n",
      "  train accuracy:\t\t99.93 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 15 of 1000 took 70.872s\n",
      "  training loss (in-iteration):\t\t0.019150\n",
      "  train accuracy:\t\t99.93 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 16 of 1000 took 71.622s\n",
      "  training loss (in-iteration):\t\t0.019743\n",
      "  train accuracy:\t\t99.94 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 17 of 1000 took 71.062s\n",
      "  training loss (in-iteration):\t\t0.020071\n",
      "  train accuracy:\t\t99.94 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 18 of 1000 took 69.743s\n",
      "  training loss (in-iteration):\t\t0.017342\n",
      "  train accuracy:\t\t99.95 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 19 of 1000 took 70.543s\n",
      "  training loss (in-iteration):\t\t0.018411\n",
      "  train accuracy:\t\t99.95 %\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 20 of 1000 took 70.068s\n",
      "  training loss (in-iteration):\t\t0.018271\n",
      "  train accuracy:\t\t99.95 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 21 of 1000 took 66.952s\n",
      "  training loss (in-iteration):\t\t0.016701\n",
      "  train accuracy:\t\t99.95 %\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 22 of 1000 took 69.596s\n",
      "  training loss (in-iteration):\t\t0.017571\n",
      "  train accuracy:\t\t99.95 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 23 of 1000 took 70.347s\n",
      "  training loss (in-iteration):\t\t0.017780\n",
      "  train accuracy:\t\t99.96 %\n",
      "  validation accuracy:\t\t99.30 %\n",
      "Epoch 24 of 1000 took 68.545s\n",
      "  training loss (in-iteration):\t\t0.017888\n",
      "  train accuracy:\t\t99.95 %\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 25 of 1000 took 75.540s\n",
      "  training loss (in-iteration):\t\t0.016969\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 26 of 1000 took 69.029s\n",
      "  training loss (in-iteration):\t\t0.015833\n",
      "  train accuracy:\t\t99.95 %\n",
      "  validation accuracy:\t\t99.34 %\n",
      "Epoch 27 of 1000 took 68.911s\n",
      "  training loss (in-iteration):\t\t0.016734\n",
      "  train accuracy:\t\t99.96 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 28 of 1000 took 67.701s\n",
      "  training loss (in-iteration):\t\t0.016893\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 29 of 1000 took 71.845s\n",
      "  training loss (in-iteration):\t\t0.017598\n",
      "  train accuracy:\t\t99.96 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 30 of 1000 took 69.943s\n",
      "  training loss (in-iteration):\t\t0.016220\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 31 of 1000 took 68.270s\n",
      "  training loss (in-iteration):\t\t0.014670\n",
      "  train accuracy:\t\t99.95 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 32 of 1000 took 70.136s\n",
      "  training loss (in-iteration):\t\t0.016535\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 33 of 1000 took 70.286s\n",
      "  training loss (in-iteration):\t\t0.015673\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 34 of 1000 took 67.178s\n",
      "  training loss (in-iteration):\t\t0.015641\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 35 of 1000 took 71.696s\n",
      "  training loss (in-iteration):\t\t0.015721\n",
      "  train accuracy:\t\t99.96 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 36 of 1000 took 70.738s\n",
      "  training loss (in-iteration):\t\t0.015490\n",
      "  train accuracy:\t\t99.98 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 37 of 1000 took 71.000s\n",
      "  training loss (in-iteration):\t\t0.014114\n",
      "  train accuracy:\t\t99.98 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 38 of 1000 took 70.336s\n",
      "  training loss (in-iteration):\t\t0.013398\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 39 of 1000 took 71.143s\n",
      "  training loss (in-iteration):\t\t0.015571\n",
      "  train accuracy:\t\t99.98 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 40 of 1000 took 70.144s\n",
      "  training loss (in-iteration):\t\t0.014929\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 41 of 1000 took 69.648s\n",
      "  training loss (in-iteration):\t\t0.014966\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 42 of 1000 took 70.618s\n",
      "  training loss (in-iteration):\t\t0.014131\n",
      "  train accuracy:\t\t99.98 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 43 of 1000 took 67.504s\n",
      "  training loss (in-iteration):\t\t0.014772\n",
      "  train accuracy:\t\t99.98 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 44 of 1000 took 71.452s\n",
      "  training loss (in-iteration):\t\t0.013975\n",
      "  train accuracy:\t\t99.97 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 45 of 1000 took 70.941s\n",
      "  training loss (in-iteration):\t\t0.013279\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 46 of 1000 took 70.807s\n",
      "  training loss (in-iteration):\t\t0.013308\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 47 of 1000 took 71.514s\n",
      "  training loss (in-iteration):\t\t0.014658\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.30 %\n",
      "Epoch 48 of 1000 took 66.297s\n",
      "  training loss (in-iteration):\t\t0.014441\n",
      "  train accuracy:\t\t99.98 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 49 of 1000 took 71.231s\n",
      "  training loss (in-iteration):\t\t0.013109\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 50 of 1000 took 68.730s\n",
      "  training loss (in-iteration):\t\t0.013199\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 51 of 1000 took 71.175s\n",
      "  training loss (in-iteration):\t\t0.015665\n",
      "  train accuracy:\t\t99.98 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 52 of 1000 took 70.611s\n",
      "  training loss (in-iteration):\t\t0.013060\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 53 of 1000 took 71.300s\n",
      "  training loss (in-iteration):\t\t0.013841\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 54 of 1000 took 67.623s\n",
      "  training loss (in-iteration):\t\t0.012190\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 55 of 1000 took 69.748s\n",
      "  training loss (in-iteration):\t\t0.012974\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 56 of 1000 took 70.459s\n",
      "  training loss (in-iteration):\t\t0.012919\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 57 of 1000 took 71.559s\n",
      "  training loss (in-iteration):\t\t0.011459\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 58 of 1000 took 70.447s\n",
      "  training loss (in-iteration):\t\t0.012109\n",
      "  train accuracy:\t\t99.98 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 59 of 1000 took 70.723s\n",
      "  training loss (in-iteration):\t\t0.012382\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 60 of 1000 took 69.939s\n",
      "  training loss (in-iteration):\t\t0.013248\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 61 of 1000 took 72.740s\n",
      "  training loss (in-iteration):\t\t0.012070\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 62 of 1000 took 68.277s\n",
      "  training loss (in-iteration):\t\t0.010977\n",
      "  train accuracy:\t\t99.98 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 63 of 1000 took 71.704s\n",
      "  training loss (in-iteration):\t\t0.012332\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.37 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 of 1000 took 69.665s\n",
      "  training loss (in-iteration):\t\t0.012653\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 65 of 1000 took 70.901s\n",
      "  training loss (in-iteration):\t\t0.011929\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 66 of 1000 took 70.342s\n",
      "  training loss (in-iteration):\t\t0.012437\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 67 of 1000 took 70.363s\n",
      "  training loss (in-iteration):\t\t0.011062\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.33 %\n",
      "Epoch 68 of 1000 took 70.647s\n",
      "  training loss (in-iteration):\t\t0.011197\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 69 of 1000 took 70.734s\n",
      "  training loss (in-iteration):\t\t0.011539\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 70 of 1000 took 68.959s\n",
      "  training loss (in-iteration):\t\t0.011586\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 71 of 1000 took 71.485s\n",
      "  training loss (in-iteration):\t\t0.011423\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 72 of 1000 took 68.093s\n",
      "  training loss (in-iteration):\t\t0.012168\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 73 of 1000 took 70.356s\n",
      "  training loss (in-iteration):\t\t0.011399\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 74 of 1000 took 71.999s\n",
      "  training loss (in-iteration):\t\t0.010073\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 75 of 1000 took 69.839s\n",
      "  training loss (in-iteration):\t\t0.010939\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 76 of 1000 took 70.121s\n",
      "  training loss (in-iteration):\t\t0.009576\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.31 %\n",
      "Epoch 77 of 1000 took 70.579s\n",
      "  training loss (in-iteration):\t\t0.010747\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 78 of 1000 took 72.074s\n",
      "  training loss (in-iteration):\t\t0.011448\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 79 of 1000 took 70.701s\n",
      "  training loss (in-iteration):\t\t0.010500\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 80 of 1000 took 72.774s\n",
      "  training loss (in-iteration):\t\t0.010190\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 81 of 1000 took 68.850s\n",
      "  training loss (in-iteration):\t\t0.009588\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 82 of 1000 took 70.768s\n",
      "  training loss (in-iteration):\t\t0.011124\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.34 %\n",
      "Epoch 83 of 1000 took 71.625s\n",
      "  training loss (in-iteration):\t\t0.011509\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 84 of 1000 took 67.660s\n",
      "  training loss (in-iteration):\t\t0.010669\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 85 of 1000 took 68.873s\n",
      "  training loss (in-iteration):\t\t0.011331\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 86 of 1000 took 69.668s\n",
      "  training loss (in-iteration):\t\t0.010066\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 87 of 1000 took 71.726s\n",
      "  training loss (in-iteration):\t\t0.011060\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 88 of 1000 took 71.512s\n",
      "  training loss (in-iteration):\t\t0.010138\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 89 of 1000 took 69.812s\n",
      "  training loss (in-iteration):\t\t0.011117\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.29 %\n",
      "Epoch 90 of 1000 took 70.798s\n",
      "  training loss (in-iteration):\t\t0.010299\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 91 of 1000 took 70.928s\n",
      "  training loss (in-iteration):\t\t0.010676\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.21 %\n",
      "Epoch 92 of 1000 took 69.303s\n",
      "  training loss (in-iteration):\t\t0.010663\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 93 of 1000 took 71.109s\n",
      "  training loss (in-iteration):\t\t0.010088\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 94 of 1000 took 70.409s\n",
      "  training loss (in-iteration):\t\t0.010834\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.33 %\n",
      "Epoch 95 of 1000 took 68.681s\n",
      "  training loss (in-iteration):\t\t0.009199\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 96 of 1000 took 71.772s\n",
      "  training loss (in-iteration):\t\t0.010671\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 97 of 1000 took 68.571s\n",
      "  training loss (in-iteration):\t\t0.010072\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 98 of 1000 took 70.530s\n",
      "  training loss (in-iteration):\t\t0.009478\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 99 of 1000 took 70.060s\n",
      "  training loss (in-iteration):\t\t0.008905\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 100 of 1000 took 70.537s\n",
      "  training loss (in-iteration):\t\t0.009582\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 101 of 1000 took 69.862s\n",
      "  training loss (in-iteration):\t\t0.009545\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 102 of 1000 took 70.438s\n",
      "  training loss (in-iteration):\t\t0.008728\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 103 of 1000 took 71.971s\n",
      "  training loss (in-iteration):\t\t0.011076\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 104 of 1000 took 69.932s\n",
      "  training loss (in-iteration):\t\t0.009532\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 105 of 1000 took 69.730s\n",
      "  training loss (in-iteration):\t\t0.009484\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 106 of 1000 took 69.644s\n",
      "  training loss (in-iteration):\t\t0.010235\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 107 of 1000 took 72.051s\n",
      "  training loss (in-iteration):\t\t0.009397\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 108 of 1000 took 70.011s\n",
      "  training loss (in-iteration):\t\t0.009108\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 109 of 1000 took 70.075s\n",
      "  training loss (in-iteration):\t\t0.008804\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 110 of 1000 took 69.129s\n",
      "  training loss (in-iteration):\t\t0.009684\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 111 of 1000 took 72.145s\n",
      "  training loss (in-iteration):\t\t0.008897\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 112 of 1000 took 69.117s\n",
      "  training loss (in-iteration):\t\t0.010092\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 113 of 1000 took 69.526s\n",
      "  training loss (in-iteration):\t\t0.008961\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 114 of 1000 took 72.270s\n",
      "  training loss (in-iteration):\t\t0.010420\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.50 %\n",
      "Epoch 115 of 1000 took 71.983s\n",
      "  training loss (in-iteration):\t\t0.008883\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 116 of 1000 took 70.615s\n",
      "  training loss (in-iteration):\t\t0.009105\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 117 of 1000 took 69.371s\n",
      "  training loss (in-iteration):\t\t0.008901\n",
      "  train accuracy:\t\t99.99 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 118 of 1000 took 69.691s\n",
      "  training loss (in-iteration):\t\t0.009840\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 119 of 1000 took 71.072s\n",
      "  training loss (in-iteration):\t\t0.009744\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 120 of 1000 took 69.638s\n",
      "  training loss (in-iteration):\t\t0.008016\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 121 of 1000 took 69.915s\n",
      "  training loss (in-iteration):\t\t0.008529\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 122 of 1000 took 70.561s\n",
      "  training loss (in-iteration):\t\t0.009496\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 123 of 1000 took 71.071s\n",
      "  training loss (in-iteration):\t\t0.009489\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 124 of 1000 took 70.435s\n",
      "  training loss (in-iteration):\t\t0.009107\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 125 of 1000 took 67.931s\n",
      "  training loss (in-iteration):\t\t0.008703\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 126 of 1000 took 72.569s\n",
      "  training loss (in-iteration):\t\t0.009350\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 of 1000 took 71.792s\n",
      "  training loss (in-iteration):\t\t0.008956\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.49 %\n",
      "Epoch 128 of 1000 took 67.461s\n",
      "  training loss (in-iteration):\t\t0.008226\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 129 of 1000 took 70.935s\n",
      "  training loss (in-iteration):\t\t0.008576\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 130 of 1000 took 68.220s\n",
      "  training loss (in-iteration):\t\t0.007689\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 131 of 1000 took 70.079s\n",
      "  training loss (in-iteration):\t\t0.009476\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.50 %\n",
      "Epoch 132 of 1000 took 69.512s\n",
      "  training loss (in-iteration):\t\t0.008405\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 133 of 1000 took 70.196s\n",
      "  training loss (in-iteration):\t\t0.008009\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 134 of 1000 took 68.934s\n",
      "  training loss (in-iteration):\t\t0.008228\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 135 of 1000 took 71.718s\n",
      "  training loss (in-iteration):\t\t0.008355\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 136 of 1000 took 69.601s\n",
      "  training loss (in-iteration):\t\t0.008023\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 137 of 1000 took 71.794s\n",
      "  training loss (in-iteration):\t\t0.007647\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 138 of 1000 took 69.395s\n",
      "  training loss (in-iteration):\t\t0.008864\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 139 of 1000 took 69.468s\n",
      "  training loss (in-iteration):\t\t0.009042\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 140 of 1000 took 70.324s\n",
      "  training loss (in-iteration):\t\t0.007480\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 141 of 1000 took 70.410s\n",
      "  training loss (in-iteration):\t\t0.008163\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 142 of 1000 took 71.374s\n",
      "  training loss (in-iteration):\t\t0.009780\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 143 of 1000 took 70.145s\n",
      "  training loss (in-iteration):\t\t0.007534\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 144 of 1000 took 71.051s\n",
      "  training loss (in-iteration):\t\t0.008318\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 145 of 1000 took 68.482s\n",
      "  training loss (in-iteration):\t\t0.008034\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.49 %\n",
      "Epoch 146 of 1000 took 71.964s\n",
      "  training loss (in-iteration):\t\t0.009301\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 147 of 1000 took 72.165s\n",
      "  training loss (in-iteration):\t\t0.007846\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 148 of 1000 took 71.133s\n",
      "  training loss (in-iteration):\t\t0.007947\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 149 of 1000 took 70.094s\n",
      "  training loss (in-iteration):\t\t0.007604\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 150 of 1000 took 70.574s\n",
      "  training loss (in-iteration):\t\t0.008558\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 151 of 1000 took 70.753s\n",
      "  training loss (in-iteration):\t\t0.008541\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 152 of 1000 took 69.000s\n",
      "  training loss (in-iteration):\t\t0.007537\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 153 of 1000 took 67.918s\n",
      "  training loss (in-iteration):\t\t0.007608\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 154 of 1000 took 70.786s\n",
      "  training loss (in-iteration):\t\t0.007171\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 155 of 1000 took 71.075s\n",
      "  training loss (in-iteration):\t\t0.007430\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 156 of 1000 took 69.106s\n",
      "  training loss (in-iteration):\t\t0.008164\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 157 of 1000 took 70.867s\n",
      "  training loss (in-iteration):\t\t0.007490\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 158 of 1000 took 70.625s\n",
      "  training loss (in-iteration):\t\t0.008418\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 159 of 1000 took 71.781s\n",
      "  training loss (in-iteration):\t\t0.007518\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 160 of 1000 took 69.438s\n",
      "  training loss (in-iteration):\t\t0.006937\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 161 of 1000 took 71.310s\n",
      "  training loss (in-iteration):\t\t0.007702\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 162 of 1000 took 70.690s\n",
      "  training loss (in-iteration):\t\t0.008386\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 163 of 1000 took 71.125s\n",
      "  training loss (in-iteration):\t\t0.007762\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 164 of 1000 took 70.037s\n",
      "  training loss (in-iteration):\t\t0.008161\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 165 of 1000 took 69.658s\n",
      "  training loss (in-iteration):\t\t0.007758\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 166 of 1000 took 69.659s\n",
      "  training loss (in-iteration):\t\t0.007165\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 167 of 1000 took 69.312s\n",
      "  training loss (in-iteration):\t\t0.007136\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 168 of 1000 took 69.882s\n",
      "  training loss (in-iteration):\t\t0.006457\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 169 of 1000 took 73.049s\n",
      "  training loss (in-iteration):\t\t0.008241\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 170 of 1000 took 69.295s\n",
      "  training loss (in-iteration):\t\t0.007282\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 171 of 1000 took 69.743s\n",
      "  training loss (in-iteration):\t\t0.007460\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.34 %\n",
      "Epoch 172 of 1000 took 69.195s\n",
      "  training loss (in-iteration):\t\t0.006685\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 173 of 1000 took 69.873s\n",
      "  training loss (in-iteration):\t\t0.006803\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 174 of 1000 took 68.944s\n",
      "  training loss (in-iteration):\t\t0.007892\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 175 of 1000 took 70.793s\n",
      "  training loss (in-iteration):\t\t0.009123\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 176 of 1000 took 71.344s\n",
      "  training loss (in-iteration):\t\t0.006554\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 177 of 1000 took 68.827s\n",
      "  training loss (in-iteration):\t\t0.006359\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 178 of 1000 took 70.374s\n",
      "  training loss (in-iteration):\t\t0.007255\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 179 of 1000 took 71.191s\n",
      "  training loss (in-iteration):\t\t0.007068\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 180 of 1000 took 69.628s\n",
      "  training loss (in-iteration):\t\t0.007057\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 181 of 1000 took 71.688s\n",
      "  training loss (in-iteration):\t\t0.007201\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 182 of 1000 took 70.696s\n",
      "  training loss (in-iteration):\t\t0.007244\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 183 of 1000 took 70.878s\n",
      "  training loss (in-iteration):\t\t0.006611\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 184 of 1000 took 68.537s\n",
      "  training loss (in-iteration):\t\t0.006416\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 185 of 1000 took 70.984s\n",
      "  training loss (in-iteration):\t\t0.008196\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 186 of 1000 took 68.143s\n",
      "  training loss (in-iteration):\t\t0.007096\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 187 of 1000 took 71.566s\n",
      "  training loss (in-iteration):\t\t0.006537\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 188 of 1000 took 70.701s\n",
      "  training loss (in-iteration):\t\t0.006941\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189 of 1000 took 69.789s\n",
      "  training loss (in-iteration):\t\t0.007454\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 190 of 1000 took 69.764s\n",
      "  training loss (in-iteration):\t\t0.006673\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 191 of 1000 took 70.278s\n",
      "  training loss (in-iteration):\t\t0.007093\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 192 of 1000 took 70.451s\n",
      "  training loss (in-iteration):\t\t0.006578\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 193 of 1000 took 71.969s\n",
      "  training loss (in-iteration):\t\t0.007268\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 194 of 1000 took 70.514s\n",
      "  training loss (in-iteration):\t\t0.006784\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 195 of 1000 took 71.154s\n",
      "  training loss (in-iteration):\t\t0.007185\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 196 of 1000 took 67.135s\n",
      "  training loss (in-iteration):\t\t0.006778\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 197 of 1000 took 71.952s\n",
      "  training loss (in-iteration):\t\t0.006883\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 198 of 1000 took 70.433s\n",
      "  training loss (in-iteration):\t\t0.008161\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.49 %\n",
      "Epoch 199 of 1000 took 70.766s\n",
      "  training loss (in-iteration):\t\t0.006974\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 200 of 1000 took 67.672s\n",
      "  training loss (in-iteration):\t\t0.007067\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 201 of 1000 took 70.717s\n",
      "  training loss (in-iteration):\t\t0.006927\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 202 of 1000 took 71.578s\n",
      "  training loss (in-iteration):\t\t0.007489\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 203 of 1000 took 70.220s\n",
      "  training loss (in-iteration):\t\t0.005998\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 204 of 1000 took 69.741s\n",
      "  training loss (in-iteration):\t\t0.006391\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 205 of 1000 took 71.261s\n",
      "  training loss (in-iteration):\t\t0.006885\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 206 of 1000 took 71.682s\n",
      "  training loss (in-iteration):\t\t0.006226\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.32 %\n",
      "Epoch 207 of 1000 took 71.170s\n",
      "  training loss (in-iteration):\t\t0.005788\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 208 of 1000 took 70.856s\n",
      "  training loss (in-iteration):\t\t0.006513\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 209 of 1000 took 68.191s\n",
      "  training loss (in-iteration):\t\t0.005892\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 210 of 1000 took 72.249s\n",
      "  training loss (in-iteration):\t\t0.007012\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.33 %\n",
      "Epoch 211 of 1000 took 71.238s\n",
      "  training loss (in-iteration):\t\t0.006424\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 212 of 1000 took 70.566s\n",
      "  training loss (in-iteration):\t\t0.005528\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 213 of 1000 took 71.776s\n",
      "  training loss (in-iteration):\t\t0.006911\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.30 %\n",
      "Epoch 214 of 1000 took 70.421s\n",
      "  training loss (in-iteration):\t\t0.007053\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 215 of 1000 took 70.275s\n",
      "  training loss (in-iteration):\t\t0.007622\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 216 of 1000 took 69.899s\n",
      "  training loss (in-iteration):\t\t0.006319\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 217 of 1000 took 70.035s\n",
      "  training loss (in-iteration):\t\t0.006774\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 218 of 1000 took 71.072s\n",
      "  training loss (in-iteration):\t\t0.007521\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 219 of 1000 took 70.237s\n",
      "  training loss (in-iteration):\t\t0.006449\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 220 of 1000 took 70.366s\n",
      "  training loss (in-iteration):\t\t0.006281\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 221 of 1000 took 70.542s\n",
      "  training loss (in-iteration):\t\t0.006248\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.33 %\n",
      "Epoch 222 of 1000 took 68.321s\n",
      "  training loss (in-iteration):\t\t0.006124\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 223 of 1000 took 70.074s\n",
      "  training loss (in-iteration):\t\t0.006729\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 224 of 1000 took 70.913s\n",
      "  training loss (in-iteration):\t\t0.006192\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 225 of 1000 took 70.724s\n",
      "  training loss (in-iteration):\t\t0.005218\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 226 of 1000 took 69.801s\n",
      "  training loss (in-iteration):\t\t0.006123\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 227 of 1000 took 70.614s\n",
      "  training loss (in-iteration):\t\t0.007395\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 228 of 1000 took 69.237s\n",
      "  training loss (in-iteration):\t\t0.006498\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 229 of 1000 took 69.903s\n",
      "  training loss (in-iteration):\t\t0.006489\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 230 of 1000 took 70.749s\n",
      "  training loss (in-iteration):\t\t0.006849\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 231 of 1000 took 69.823s\n",
      "  training loss (in-iteration):\t\t0.007456\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 232 of 1000 took 70.164s\n",
      "  training loss (in-iteration):\t\t0.006260\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 233 of 1000 took 71.365s\n",
      "  training loss (in-iteration):\t\t0.006472\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 234 of 1000 took 68.745s\n",
      "  training loss (in-iteration):\t\t0.006279\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 235 of 1000 took 69.208s\n",
      "  training loss (in-iteration):\t\t0.006501\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 236 of 1000 took 70.473s\n",
      "  training loss (in-iteration):\t\t0.005797\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 237 of 1000 took 70.007s\n",
      "  training loss (in-iteration):\t\t0.006555\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 238 of 1000 took 71.512s\n",
      "  training loss (in-iteration):\t\t0.007031\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 239 of 1000 took 69.043s\n",
      "  training loss (in-iteration):\t\t0.006034\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 240 of 1000 took 69.729s\n",
      "  training loss (in-iteration):\t\t0.005225\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 241 of 1000 took 69.217s\n",
      "  training loss (in-iteration):\t\t0.006238\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 242 of 1000 took 70.124s\n",
      "  training loss (in-iteration):\t\t0.005475\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 243 of 1000 took 71.725s\n",
      "  training loss (in-iteration):\t\t0.005397\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 244 of 1000 took 69.696s\n",
      "  training loss (in-iteration):\t\t0.005481\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 245 of 1000 took 70.443s\n",
      "  training loss (in-iteration):\t\t0.005271\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 246 of 1000 took 70.669s\n",
      "  training loss (in-iteration):\t\t0.006383\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 247 of 1000 took 71.540s\n",
      "  training loss (in-iteration):\t\t0.007027\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 248 of 1000 took 68.369s\n",
      "  training loss (in-iteration):\t\t0.005986\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 249 of 1000 took 72.491s\n",
      "  training loss (in-iteration):\t\t0.006417\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 250 of 1000 took 69.022s\n",
      "  training loss (in-iteration):\t\t0.004952\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251 of 1000 took 70.096s\n",
      "  training loss (in-iteration):\t\t0.005705\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 252 of 1000 took 69.434s\n",
      "  training loss (in-iteration):\t\t0.006112\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 253 of 1000 took 68.447s\n",
      "  training loss (in-iteration):\t\t0.005653\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.33 %\n",
      "Epoch 254 of 1000 took 71.458s\n",
      "  training loss (in-iteration):\t\t0.007209\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 255 of 1000 took 70.690s\n",
      "  training loss (in-iteration):\t\t0.005535\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 256 of 1000 took 71.213s\n",
      "  training loss (in-iteration):\t\t0.007527\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 257 of 1000 took 67.898s\n",
      "  training loss (in-iteration):\t\t0.004948\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 258 of 1000 took 71.150s\n",
      "  training loss (in-iteration):\t\t0.007194\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 259 of 1000 took 69.923s\n",
      "  training loss (in-iteration):\t\t0.005450\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 260 of 1000 took 70.975s\n",
      "  training loss (in-iteration):\t\t0.006722\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 261 of 1000 took 69.408s\n",
      "  training loss (in-iteration):\t\t0.006435\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 262 of 1000 took 69.944s\n",
      "  training loss (in-iteration):\t\t0.004927\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 263 of 1000 took 69.814s\n",
      "  training loss (in-iteration):\t\t0.005226\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 264 of 1000 took 70.141s\n",
      "  training loss (in-iteration):\t\t0.006107\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 265 of 1000 took 69.578s\n",
      "  training loss (in-iteration):\t\t0.005459\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 266 of 1000 took 69.870s\n",
      "  training loss (in-iteration):\t\t0.006432\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 267 of 1000 took 68.630s\n",
      "  training loss (in-iteration):\t\t0.005647\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 268 of 1000 took 69.825s\n",
      "  training loss (in-iteration):\t\t0.005198\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 269 of 1000 took 72.457s\n",
      "  training loss (in-iteration):\t\t0.005855\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 270 of 1000 took 68.077s\n",
      "  training loss (in-iteration):\t\t0.006425\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 271 of 1000 took 72.098s\n",
      "  training loss (in-iteration):\t\t0.005124\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 272 of 1000 took 69.778s\n",
      "  training loss (in-iteration):\t\t0.005671\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 273 of 1000 took 71.408s\n",
      "  training loss (in-iteration):\t\t0.005781\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 274 of 1000 took 68.957s\n",
      "  training loss (in-iteration):\t\t0.006168\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 275 of 1000 took 70.610s\n",
      "  training loss (in-iteration):\t\t0.005601\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 276 of 1000 took 67.929s\n",
      "  training loss (in-iteration):\t\t0.005413\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 277 of 1000 took 69.653s\n",
      "  training loss (in-iteration):\t\t0.005719\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 278 of 1000 took 69.929s\n",
      "  training loss (in-iteration):\t\t0.005421\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 279 of 1000 took 70.789s\n",
      "  training loss (in-iteration):\t\t0.006289\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 280 of 1000 took 68.498s\n",
      "  training loss (in-iteration):\t\t0.006060\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 281 of 1000 took 69.659s\n",
      "  training loss (in-iteration):\t\t0.005208\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 282 of 1000 took 71.478s\n",
      "  training loss (in-iteration):\t\t0.007123\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 283 of 1000 took 69.515s\n",
      "  training loss (in-iteration):\t\t0.007064\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 284 of 1000 took 67.798s\n",
      "  training loss (in-iteration):\t\t0.006649\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 285 of 1000 took 70.312s\n",
      "  training loss (in-iteration):\t\t0.005384\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 286 of 1000 took 69.285s\n",
      "  training loss (in-iteration):\t\t0.004878\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 287 of 1000 took 72.806s\n",
      "  training loss (in-iteration):\t\t0.006863\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 288 of 1000 took 68.226s\n",
      "  training loss (in-iteration):\t\t0.006140\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 289 of 1000 took 73.031s\n",
      "  training loss (in-iteration):\t\t0.005317\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 290 of 1000 took 70.315s\n",
      "  training loss (in-iteration):\t\t0.005795\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 291 of 1000 took 70.273s\n",
      "  training loss (in-iteration):\t\t0.006023\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 292 of 1000 took 70.744s\n",
      "  training loss (in-iteration):\t\t0.005685\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 293 of 1000 took 70.396s\n",
      "  training loss (in-iteration):\t\t0.006739\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 294 of 1000 took 70.716s\n",
      "  training loss (in-iteration):\t\t0.006824\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 295 of 1000 took 71.736s\n",
      "  training loss (in-iteration):\t\t0.005758\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 296 of 1000 took 69.616s\n",
      "  training loss (in-iteration):\t\t0.005801\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 297 of 1000 took 69.334s\n",
      "  training loss (in-iteration):\t\t0.005336\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 298 of 1000 took 69.550s\n",
      "  training loss (in-iteration):\t\t0.005348\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 299 of 1000 took 72.685s\n",
      "  training loss (in-iteration):\t\t0.005683\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 300 of 1000 took 70.733s\n",
      "  training loss (in-iteration):\t\t0.006089\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 301 of 1000 took 70.623s\n",
      "  training loss (in-iteration):\t\t0.005163\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 302 of 1000 took 70.275s\n",
      "  training loss (in-iteration):\t\t0.005598\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 303 of 1000 took 70.613s\n",
      "  training loss (in-iteration):\t\t0.004873\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 304 of 1000 took 69.663s\n",
      "  training loss (in-iteration):\t\t0.005793\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 305 of 1000 took 69.704s\n",
      "  training loss (in-iteration):\t\t0.005706\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 306 of 1000 took 69.449s\n",
      "  training loss (in-iteration):\t\t0.005576\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 307 of 1000 took 70.586s\n",
      "  training loss (in-iteration):\t\t0.006390\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 308 of 1000 took 71.104s\n",
      "  training loss (in-iteration):\t\t0.005563\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 309 of 1000 took 69.949s\n",
      "  training loss (in-iteration):\t\t0.004522\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 310 of 1000 took 70.743s\n",
      "  training loss (in-iteration):\t\t0.005718\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 311 of 1000 took 71.626s\n",
      "  training loss (in-iteration):\t\t0.005359\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 312 of 1000 took 70.150s\n",
      "  training loss (in-iteration):\t\t0.005679\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313 of 1000 took 68.450s\n",
      "  training loss (in-iteration):\t\t0.005779\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 314 of 1000 took 71.844s\n",
      "  training loss (in-iteration):\t\t0.005386\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 315 of 1000 took 70.485s\n",
      "  training loss (in-iteration):\t\t0.005540\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 316 of 1000 took 68.953s\n",
      "  training loss (in-iteration):\t\t0.006480\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 317 of 1000 took 68.068s\n",
      "  training loss (in-iteration):\t\t0.005490\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 318 of 1000 took 71.986s\n",
      "  training loss (in-iteration):\t\t0.006539\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 319 of 1000 took 71.116s\n",
      "  training loss (in-iteration):\t\t0.005617\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 320 of 1000 took 68.699s\n",
      "  training loss (in-iteration):\t\t0.006471\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 321 of 1000 took 69.443s\n",
      "  training loss (in-iteration):\t\t0.005355\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 322 of 1000 took 68.608s\n",
      "  training loss (in-iteration):\t\t0.005754\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 323 of 1000 took 67.796s\n",
      "  training loss (in-iteration):\t\t0.005714\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 324 of 1000 took 69.647s\n",
      "  training loss (in-iteration):\t\t0.006592\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 325 of 1000 took 71.026s\n",
      "  training loss (in-iteration):\t\t0.004859\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 326 of 1000 took 67.690s\n",
      "  training loss (in-iteration):\t\t0.006153\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 327 of 1000 took 72.320s\n",
      "  training loss (in-iteration):\t\t0.005663\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 328 of 1000 took 71.740s\n",
      "  training loss (in-iteration):\t\t0.005772\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 329 of 1000 took 69.497s\n",
      "  training loss (in-iteration):\t\t0.004117\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 330 of 1000 took 69.950s\n",
      "  training loss (in-iteration):\t\t0.005300\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 331 of 1000 took 68.214s\n",
      "  training loss (in-iteration):\t\t0.005238\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 332 of 1000 took 71.625s\n",
      "  training loss (in-iteration):\t\t0.005174\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.51 %\n",
      "Epoch 333 of 1000 took 70.858s\n",
      "  training loss (in-iteration):\t\t0.005137\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 334 of 1000 took 68.855s\n",
      "  training loss (in-iteration):\t\t0.005736\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 335 of 1000 took 71.006s\n",
      "  training loss (in-iteration):\t\t0.005526\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 336 of 1000 took 70.855s\n",
      "  training loss (in-iteration):\t\t0.005400\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 337 of 1000 took 71.066s\n",
      "  training loss (in-iteration):\t\t0.005844\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 338 of 1000 took 71.349s\n",
      "  training loss (in-iteration):\t\t0.005562\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.37 %\n",
      "Epoch 339 of 1000 took 69.578s\n",
      "  training loss (in-iteration):\t\t0.005936\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 340 of 1000 took 69.194s\n",
      "  training loss (in-iteration):\t\t0.005241\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 341 of 1000 took 71.089s\n",
      "  training loss (in-iteration):\t\t0.005593\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 342 of 1000 took 69.969s\n",
      "  training loss (in-iteration):\t\t0.005379\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 343 of 1000 took 71.545s\n",
      "  training loss (in-iteration):\t\t0.004670\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 344 of 1000 took 70.982s\n",
      "  training loss (in-iteration):\t\t0.005772\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 345 of 1000 took 71.516s\n",
      "  training loss (in-iteration):\t\t0.006412\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 346 of 1000 took 67.793s\n",
      "  training loss (in-iteration):\t\t0.005368\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 347 of 1000 took 70.918s\n",
      "  training loss (in-iteration):\t\t0.004028\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 348 of 1000 took 70.776s\n",
      "  training loss (in-iteration):\t\t0.004865\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.40 %\n",
      "Epoch 349 of 1000 took 70.037s\n",
      "  training loss (in-iteration):\t\t0.005700\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 350 of 1000 took 69.770s\n",
      "  training loss (in-iteration):\t\t0.006396\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 351 of 1000 took 68.655s\n",
      "  training loss (in-iteration):\t\t0.005063\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 352 of 1000 took 69.149s\n",
      "  training loss (in-iteration):\t\t0.005293\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.38 %\n",
      "Epoch 353 of 1000 took 67.847s\n",
      "  training loss (in-iteration):\t\t0.005952\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 354 of 1000 took 68.545s\n",
      "  training loss (in-iteration):\t\t0.004540\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.44 %\n",
      "Epoch 355 of 1000 took 70.492s\n",
      "  training loss (in-iteration):\t\t0.005620\n",
      "  train accuracy:\t\t100.00 %\n",
      "  validation accuracy:\t\t99.43 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f65848e47a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_err_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vardges/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 1000 #amount of passes through the data\n",
    "loss = []\n",
    "batch_size = 50 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\n",
    "    loss.append(train_err / train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA48AAAImCAYAAADzDb+dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRFYkj0IIIYQQQgghsvL/AAVzgs+KslokAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69706a8470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"#iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(loss, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t99.46 %\n",
      "Achievement unlocked: 80lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 99:\n",
    "    print (\"Achievement unlocked: 80lvl Warlock!\")\n",
    "else:\n",
    "    print (\"We need more magic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now improve it!\n",
    "\n",
    "* Moar layers!\n",
    "* Moar units!\n",
    "* Different nonlinearities!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It worked around 8 hours for this, but even with 20 minutes test accuracy was 99.25, so I am still 80lvl Warlock now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
